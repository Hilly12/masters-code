{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import prifair as pf\n",
    "import torch\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  income  \n",
       "0              40  United-States       0  \n",
       "1              50  United-States       0  \n",
       "2              40  United-States       1  \n",
       "3              40  United-States       1  \n",
       "4              30  United-States       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/adult.csv\")\n",
    "df[\"income\"] = df[\"income\"].map({\"<=50K\": 0, \">50K\": 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aahil/Desktop/PriFair/venv/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def init_check(df):\n",
    "    columns = df.columns    \n",
    "    lst = []\n",
    "    for feature in columns : \n",
    "        dtype = df[feature].dtypes\n",
    "        num_null = df[feature].isnull().sum()\n",
    "        num_unique = df[feature].nunique()\n",
    "        lst.append([feature, dtype, num_null, num_unique])\n",
    "    \n",
    "    check_df = pd.DataFrame(lst)\n",
    "    check_df.columns = ['feature','dtype','num_null','num_unique']\n",
    "    check_df = check_df.sort_values(by='dtype', axis=0, ascending=True)\n",
    "    \n",
    "    return check_df\n",
    "\n",
    "X = df[df.columns.drop([\"income\", \"fnlwgt\"])]\n",
    "y = df[\"income\"]\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "encoded = X[categorical_columns].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "X = X.drop(columns=categorical_columns, axis=1)\n",
    "X = pd.concat([X, encoded], axis=1)\n",
    "\n",
    "perm = np.random.permutation(X.shape[0])\n",
    "X = X.iloc[perm]\n",
    "y = y.iloc[perm]\n",
    "\n",
    "X_train = X[:30000]\n",
    "X_student = X[30000:40000]\n",
    "X_test = X[40000:]\n",
    "y_train = y[:30000]\n",
    "y_student = y[30000:40000]\n",
    "y_test = y[40000:]\n",
    "\n",
    "train_gender = X_train[\"gender\"].to_numpy()\n",
    "test_gender = X_test[\"gender\"].to_numpy()\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_student = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 24),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 24),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 2),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(list(zip(torch.FloatTensor(X_train), y_train.astype(int))), batch_size=64, shuffle=True)\n",
    "student_loader = torch.utils.data.DataLoader(list(zip(torch.FloatTensor(X_student), y_student.astype(int))), batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(list(zip(torch.FloatTensor(X_test), y_test.astype(int))), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:00<00:00, 1349.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.47 Train Acc@1: 77.15 Val Loss: 72.22 Val Acc@1: 78.31 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:00<00:00, 1377.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.40 Train Acc@1: 81.05 Val Loss: 270.37 Val Acc@1: 78.31 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:00<00:00, 1552.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.38 Train Acc@1: 81.91 Val Loss: 609.24 Val Acc@1: 78.28 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:00<00:00, 1528.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train Loss: 0.37 Train Acc@1: 82.71 Val Loss: 956.58 Val Acc@1: 77.67 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:00<00:00, 1471.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.37 Train Acc@1: 82.79 Val Loss: 1285.50 Val Acc@1: 77.00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_vanilla, metrics_vanilla = pf.training.train_vanilla(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    model_class=Model,\n",
    "    optim_class=optim.NAdam,\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aahil/Desktop/PriFair/venv/lib/python3.9/site-packages/opacus/privacy_engine.py:114: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/Users/aahil/Desktop/PriFair/venv/lib/python3.9/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/234 [00:00<?, ?it/s]/Users/aahil/Desktop/PriFair/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "469it [00:01, 444.06it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.71 Train Acc@1: 76.02 Val Loss: 128.49 Val Acc@1: 76.94 (ε = 0.92, δ = 1e-05) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 537.23it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.68 Train Acc@1: 76.28 Val Loss: 198.86 Val Acc@1: 76.94 (ε = 0.96, δ = 1e-05) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 528.76it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.70 Train Acc@1: 76.06 Val Loss: 214.76 Val Acc@1: 76.94 (ε = 1.00, δ = 1e-05) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_dpsgd, metrics_dpsgd = pf.training.train_dpsgd(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    model_class=Model,\n",
    "    optim_class=optim.NAdam,\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    target_epsilon=1.0,\n",
    "    target_delta=1e-5,\n",
    "    max_grad_norm=1.2,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:01<00:00, 361.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.65 Train Acc@1: 76.07 Val Loss: 12831.85 Val Acc@1: 75.87 (ε = 0.92, δ = 1e-05) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:01<00:00, 453.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.64 Train Acc@1: 76.00 Val Loss: 22649.39 Val Acc@1: 75.87 (ε = 0.96, δ = 1e-05) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:01<00:00, 444.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.67 Train Acc@1: 75.92 Val Loss: 32714.54 Val Acc@1: 75.87 (ε = 1.00, δ = 1e-05) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_dpsgdf, metrics_dpsgdf = pf.training.train_dpsgdf(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    model_class=Model,\n",
    "    optim_class=optim.NAdam,\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    target_epsilon=1.0,\n",
    "    target_delta=1e-5,\n",
    "    base_clipping_threshold=1.2,\n",
    "    epochs=3,\n",
    "    group_labels=torch.LongTensor(train_gender)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighing...\n",
      "Training Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 477.22it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.67 Train Acc@1: 79.13 Val Loss: 17780.95 Val Acc@1: 75.87 (ε = 0.77, δ = 1e-05) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 504.59it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.63 Train Acc@1: 79.37 Val Loss: 21067.06 Val Acc@1: 75.87 (ε = 0.80, δ = 1e-05) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:00, 528.75it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.63 Train Acc@1: 79.51 Val Loss: 21925.44 Val Acc@1: 75.87 (ε = 0.84, δ = 1e-05) \n"
     ]
    }
   ],
   "source": [
    "model_dpsgd_w, metrics_dpsgd_w = pf.training.train_dpsgd_weighted(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    model_class=Model,\n",
    "    optim_class=optim.NAdam,\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    target_epsilon=1.0,\n",
    "    target_delta=1e-5,\n",
    "    max_grad_norm=1.2,\n",
    "    epochs=3,\n",
    "    weighting=\"sensitive_attr\",\n",
    "    relative_weight_bound=10.0,\n",
    "    labels=train_gender\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 10 Teacher Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 26.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 1 Loss: 0.40 Acc@1: 81.96 Val Loss: 49553.25 Val Acc@1: 77.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 31.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 2 Loss: 0.40 Acc@1: 80.96 Val Loss: 76651.38 Val Acc@1: 76.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 26.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 3 Loss: 0.41 Acc@1: 80.74 Val Loss: 85644.89 Val Acc@1: 76.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 30.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 4 Loss: 0.41 Acc@1: 80.56 Val Loss: 69252.08 Val Acc@1: 76.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 5 Loss: 0.42 Acc@1: 80.59 Val Loss: 22614.89 Val Acc@1: 76.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 6 Loss: 0.40 Acc@1: 81.56 Val Loss: 51871.89 Val Acc@1: 76.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 27.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 7 Loss: 0.40 Acc@1: 82.47 Val Loss: 110401.89 Val Acc@1: 76.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 27.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 8 Loss: 0.43 Acc@1: 79.14 Val Loss: 31593.74 Val Acc@1: 76.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 9 Loss: 0.40 Acc@1: 81.11 Val Loss: 41032.03 Val Acc@1: 76.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model: 10 Loss: 0.41 Acc@1: 81.00 Val Loss: 57331.15 Val Acc@1: 76.12\n",
      "Aggregating Teachers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing a suitable sigma for GNMax.......\n",
      "Data Dependent Epsilon: 5.025687586068838\n",
      "Training Student Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1339.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.10 Train Acc@1: 98.55 Val Loss: 52701.44 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1414.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 50311.66 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1440.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 55790.83 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1381.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 55146.90 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1477.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 53165.70 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1472.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 57493.60 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1470.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 60070.43 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1480.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 55131.54 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1490.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 56646.33 Val Acc@1: 75.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 1121.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.02 Train Acc@1: 99.78 Val Loss: 54009.85 Val Acc@1: 75.87 \n"
     ]
    }
   ],
   "source": [
    "model_pate, metrics_pate = pf.training.train_pate(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    student_loader=student_loader,\n",
    "    model_class=Model,\n",
    "    optim_class=optim.NAdam,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    n_teachers=10,\n",
    "    target_epsilon=5.0,\n",
    "    target_delta=1e-5,\n",
    "    epochs=10,\n",
    "    epsilon_error_tolerance=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.371183\n",
      "Test Accuracy: 75.842570\n",
      "Test Accuracy: 75.842570\n",
      "Test Accuracy: 75.842570\n",
      "Test Accuracy: 75.842570\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXLklEQVR4nO3de5RddZmn8eclJIZwNwQmEIeKSwwQYQIU4eJqDUQFQbkow8Cyu9MN08CMgqCojIgggwvaYYmgDHRsEHrAgAa5NMyoQCerGZpbFYkQBBoaAwkDpggQJBJNwjt/7F3bQ6USTlJ1Lsl5PmtlnX3f795Vqe/Zv32LzESSJIDNWl2AJKl9GAqSpIqhIEmqGAqSpIqhIEmqbN7qAoZihx12yK6urlaXIUkbld7e3lcyc9xg4zbqUOjq6qKnp6fVZUjSRiUinl/bOJuPJEkVQ0GSVDEUJEmVjfqcgiStXLmSxYsXs2LFilaX0nZGjx7NhAkTGDlyZN3zGAqSNmqLFy9m6623pquri4hodTltIzNZunQpixcvZuLEiXXPZ/ORpI3aihUrGDt2rIEwQEQwduzY9T6CMhQkbfQMhMFtyH4xFCRJFc8pSNqkdJ1z17Aub+ElR77rNBHB5z73OW644QYAVq1axfjx4znggAO488471zrf3LlzufTSS9c5TbN5pCBJQ7TllluyYMEC3nrrLQDuvvtudtlllxZXtWEMBUkaBkcccQR33VUcpcyaNYsTTzyxGvfwww9z0EEHsc8++3DwwQfz9NNPrzH/8uXLOemkk5g6dSr77LMPt99+e9Nqr2UoSNIwOOGEE7jppptYsWIFjz32GAcccEA1bvfdd+e+++5j3rx5XHjhhXz9619fY/5vf/vbHHrooTz88MPMmTOHr3zlKyxfvryZmwB4TkGShsXee+/NwoULmTVrFkccccQ7xi1btowZM2bwzDPPEBGsXLlyjfl/+ctfcscdd3DppZcCxaW2L7zwAnvssUdT6u9nKEjSMDnqqKM4++yzmTt3LkuXLq2Gn3feeRxyyCHceuutLFy4kGnTpq0xb2Zyyy23MGnSpCZWvCabjyRpmJx00kmcf/757LXXXu8YvmzZsurE83XXXTfovIcddhjf//73yUwA5s2b19Ba18YjBUmblHouIW2UCRMmcMYZZ6wx/Ktf/SozZszgoosu4sgjB6/vvPPO48wzz2Tvvffm7bffZuLEiS25VDX6U2lj1N3dnb5kR+psTz75ZNPb3Tcmg+2fiOjNzO7Bprf5SJJUMRQkSRVDQZJUMRQkSRVDQZJUMRQkSRXvU5C0ablg22Fe3rJ3nWTEiBHvuGHttttuo6ura3jrKHV1ddHT08MOO+zQkOUbCpI0RFtssQXz589vdRnDwuYjSWqA3t5ePvrRj7Lffvtx2GGH8dJLLwEwbdo0zjrrLLq7u9ljjz145JFH+MxnPsNuu+3GN77xjWr+Y445hv3224/Jkyczc+bMQddxww03MHXqVKZMmcKpp57K6tWrh1y3oSBJQ/TWW28xZcoUpkyZwrHHHsvKlSs5/fTTmT17Nr29vZx00kmce+651fSjRo2ip6eH0047jaOPPporr7ySBQsWcN1111UP0rv22mvp7e2lp6eHK6644h0P2IPiTuWbb76Z+++/n/nz5zNixAhuvPHGIW+LzUeSNEQDm48WLFjAggUL+PjHPw7A6tWrGT9+fDX+qKOOAmCvvfZi8uTJ1bj3v//9LFq0iLFjx3LFFVdw6623ArBo0SKeeeYZxo4dWy3j3nvvpbe3l/333x8ogmnHHXcc8rYYCpI0zDKTyZMn88ADDww6/j3veQ8Am222WdXd379q1Srmzp3LPffcwwMPPMCYMWOYNm0aK1asWGMdM2bM4OKLLx7W2m0+kqRhNmnSJPr6+qpQWLlyJU888UTd8y9btoztt9+eMWPG8NRTT/Hggw+uMc306dOZPXs2S5YsAeDVV1/l+eefH3LtDTtSiIhrgU8BSzLzQ+Ww9wI3A13AQuD4zHwtIgK4HDgC+D3wV5n5aKNqk7QJq+MS0kYbNWoUs2fP5owzzmDZsmWsWrWKM888k8mTJ9c1/+GHH87VV1/NHnvswaRJkzjwwAPXmGbPPffkoosu4hOf+ARvv/02I0eO5Morr2TXXXcdUu0Ne3R2RHwEeBP4h5pQ+A7wamZeEhHnANtn5tci4gjgdIpQOAC4PDMPWNuy+/nobEk+Onvd2ubR2Zn5z8CrAwYfDVxfdl8PHFMz/B+y8CCwXUSMR5LUVM0+p7BTZr5Udr8M7FR27wIsqplucTlsDRFxSkT0RERPX19f4yqVpA7UshPNWbRbrXfbVWbOzMzuzOweN25cAyqTtLHZmN8g2Ugbsl+aHQq/7W8WKj+XlMNfBN5XM92EcpgkrdPo0aNZunSpwTBAZrJ06VJGjx69XvM1+z6FO4AZwCXl5+01w78QETdRnGheVtPMJElrNWHCBBYvXozNyWsaPXo0EyZMWK95GnlJ6ixgGrBDRCwGzqcIg59ExMnA88Dx5eT/m+LKo2cpLkn960bVJWnTMnLkSCZOnNjqMjYZDQuFzDxxLaOmDzJtAp9vVC2SpPp4R7MkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqzX50dtvoOueuDZpv4SVHDnMlktQ+PFKQJFUMBUlSpWObj7Qmm9QGtyH7xX0yuE15v2wq+8QjBUlSxVCQJFUMBUlSxVCQJFUMBUlSxVCQJFUMBUlSxVCQJFUMBUlSxVCQJFUMBUlSpSWhEBFnRcQTEbEgImZFxOiImBgRD0XEsxFxc0SMakVtktTJmh4KEbELcAbQnZkfAkYAJwB/C1yWmR8AXgNObnZtktTpWtV8tDmwRURsDowBXgIOBWaX468HjmlNaZLUuZoeCpn5InAp8AJFGCwDeoHXM3NVOdliYJdm1yZJna4VzUfbA0cDE4GdgS2Bw9dj/lMioicievr6+hpUpSR1plY0H30M+E1m9mXmSuBnwIeB7crmJIAJwIuDzZyZMzOzOzO7x40b15yKJalDtCIUXgAOjIgxERHAdODXwBzguHKaGcDtLahNkjpaK84pPERxQvlR4PGyhpnA14AvRcSzwFjgmmbXJkmdriXvaM7M84HzBwx+DpjagnIkSSXvaJYkVQwFSVLFUJAkVQwFSVLFUJAkVVpy9dFG7YJtN3C+ZcNbhyQ1gEcKkqSKoSBJqhgKkqSKoSBJqhgKkqSKoSBJqrxrKETEpyPC8JCkDlDPH/v/BDwTEd+JiN0bXZAkqXXe9ea1zPzziNgGOBG4LiIS+BEwKzN/1+gCtRHwhr41uU8GtyH7xX2ylvkas1/qahbKzDcoXoxzEzAeOBZ4NCJOb0hVkqSWqOecwlERcSswFxgJTM3MTwL/AfhyY8uTJDVTPc8++ixwWWb+c+3AzPx9RJzcmLIkSa1QTyhcALzU3xMRWwA7ZebCzLy3UYVJkpqvnnMKPwXerulfXQ6TJG1i6gmFzTPzj/09ZfeoxpUkSWqVekKhLyKO6u+JiKOBVxpXkiSpVeo5p3AacGNE/AAIYBHwlw2tSpLUEvXcvPZvwIERsVXZ/2bDq5IktURdr+OMiCOBycDoiAAgMy9sYF2SpBao5+a1qymef3Q6RfPRfwR2bXBdkqQWqOdE88GZ+ZfAa5n5LeAg4IONLUuS1Ar1hMKK8vP3EbEzsJLi+UeSpE1MPaHwjxGxHfA/gEeBhcCPh7LSiNguImZHxFMR8WREHBQR742IuyPimfJz+6GsQ5K0/tYZCuXLde7NzNcz8xaKcwm7Z+Y3h7jey4GfZ+buFA/WexI4p1zXbsC9Zb8kqYnWGQqZ+TZwZU3/HzJzSA/xjohtgY8A15TL/GNmvg4cDVxfTnY9cMxQ1iNJWn/1NB/dGxGfjf5rUYduItAH/Cgi5kXE30fElhQP2et/8N7LwE6DzRwRp0RET0T09PX1DVNJkiSoLxROpXgA3h8i4o2I+F1EvDGEdW4O7AtclZn7AMsZ0FSUmQnkYDNn5szM7M7M7nHjxg2hDEnSQO8aCpm5dWZulpmjMnObsn+bIaxzMbA4Mx8q+2dThMRvI2I8QPm5ZAjrkCRtgHe9ozkiPjLY8IEv3alXZr4cEYsiYlJmPg1MB35d/psBXFJ+3r4hy5ckbbh6HnPxlZru0cBUoBc4dAjrPZ3iIXujgOeAv6Y4avlJ+Ta354Hjh7B8SdIGqOeBeJ+u7Y+I9wHfG8pKM3M+0D3IqOlDWa4kaWjqOdE80GJgj+EuRJLUevWcU/g+f7oSaDNgCsWdzZKkTUw95xR6arpXAbMy8/4G1SNJaqF6QmE2sCIzVwNExIiIGJOZv29saZKkZqvrjmZgi5r+LYB7GlOOJKmV6gmF0bWv4Cy7xzSuJElSq9QTCssjYt/+nojYD3ircSVJklqlnnMKZwI/jYj/R/E6zn9H8XpOSdImpp6b1x6JiN2BSeWgpzNzZWPLkiS1wrs2H0XE54EtM3NBZi4AtoqI/9r40iRJzVbPOYW/KV+CA0Bmvgb8TcMqkiS1TD2hMKL2BTsRMQIY1biSJEmtUs+J5p8DN0fE35X9pwL/p3ElSZJapZ5Q+BpwCnBa2f8YxRVIkqRNTD1vXnsbeAhYSPEuhUOBJxtbliSpFdZ6pBARHwROLP+9AtwMkJmHNKc0SVKzrav56CngPuBTmfksQESc1ZSqJEktsa7mo88ALwFzIuKHETGd4o5mSdImaq2hkJm3ZeYJwO7AHIrHXewYEVdFxCeaVJ8kqYnqOdG8PDN/XL6reQIwj+KKJEnSJma93tGcma9l5szMnN6ogiRJrbNeoSBJ2rQZCpKkiqEgSaoYCpKkiqEgSaoYCpKkiqEgSaq0LBQiYkREzIuIO8v+iRHxUEQ8GxE3R4Qv8pGkJmvlkcIXeecjuP8WuCwzPwC8BpzckqokqYO1JBQiYgJwJPD3ZX9QvKdhdjnJ9cAxrahNkjpZq44Uvgd8FXi77B8LvJ6Zq8r+xcAug80YEadERE9E9PT19TW8UEnqJE0PhYj4FLAkM3s3ZP7y2Uvdmdk9bty4Ya5OkjpbPe9oHm4fBo6KiCOA0cA2wOXAdhGxeXm0MAF4sQW1SVJHa/qRQmb+t8yckJldwAnAP2Xm5yje2XBcOdkM4PZm1yZJna6d7lP4GvCliHiW4hzDNS2uR5I6TiuajyqZOReYW3Y/B0xtZT2S1Ona6UhBktRihoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqWIoSJIqTQ+FiHhfRMyJiF9HxBMR8cVy+Hsj4u6IeKb83L7ZtUlSp2vFkcIq4MuZuSdwIPD5iNgTOAe4NzN3A+4t+yVJTdT0UMjMlzLz0bL7d8CTwC7A0cD15WTXA8c0uzZJ6nQtPacQEV3APsBDwE6Z+VI56mVgp7XMc0pE9ERET19fX3MKlaQO0bJQiIitgFuAMzPzjdpxmZlADjZfZs7MzO7M7B43blwTKpWkztGSUIiIkRSBcGNm/qwc/NuIGF+OHw8saUVtktTJWnH1UQDXAE9m5ndrRt0BzCi7ZwC3N7s2Sep0m7dgnR8G/gJ4PCLml8O+DlwC/CQiTgaeB45vQW2S1NGaHgqZ+X+BWMvo6c2sRZL0Tt7RLEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpIqhIEmqGAqSpEpbhUJEHB4RT0fEsxFxTqvrkaRO0zahEBEjgCuBTwJ7AidGxJ6trUqSOkvbhAIwFXg2M5/LzD8CNwFHt7gmSeookZmtrgGAiDgOODwz/3PZ/xfAAZn5hQHTnQKcUvZOAp5uaqGwA/BKk9fZ7twna3KfDM79sqZW7JNdM3PcYCM2b3IhQ5aZM4GZrVp/RPRkZner1t+O3Cdrcp8Mzv2ypnbbJ+3UfPQi8L6a/gnlMElSk7RTKDwC7BYREyNiFHACcEeLa5KkjtI2zUeZuSoivgD8AhgBXJuZT7S4rMG0rOmqjblP1uQ+GZz7ZU1ttU/a5kSzJKn12qn5SJLUYoaCJKnScaEQEXMi4rABw86MiKvWczlH9T+KIyIuiIizy+7rynsu2l5ErI6I+RHxRET8KiK+HBGbleOmRcSycvyTEXH+WpZxUkQ8HhGPRcSCiDi6ZtyXIuKpcvyvIuK7ETGyHLewHP54RPw6Ii6KiNHN2fKqvo1i+8vfrxfLWuZHxCWduj8i4osR8b2a/r+LiHtq+k+PiCuGcbdskJp9uSAifhoRY8rhm0dEX//PMCLOrfm5rq7pPmOQn/v8iNiu4cVnZkf9o7jx7UcDhj0IfGQIy7wAOLvsvg44rtXbWWfdb9Z07wjcA3yr7J8G3Fl2bwk8A+w7YP4JwL8B25b9WwETy+7TgJ8D25X9o4BzgG3K/oXADjXz/Ri43u1f9+9Xp+8PoBt4uKb/QYorF0eU/bOAE5r5e1THvrwR+FLZ/Ung/nI/xdrmaebPfeC/jjtSAGYDR0Zx2SsR0QXsTPGspZ7yW9K3+icuv8F8KyIeLb/F7F4O/6uI+MG6VhQR34yIR8pvCzMjIhq3WUOTmUsoAvMLA+vMzOVAL/CBAbPtCPwOeLOc7s3M/E057lzgv2Tm6+W4P2bmJZn5xiDrfpPij8YxEfHe4duq+nX69g/UxvtjPvDBiNgiIrYF3iqH7VWOP5jij247uY8/7asTgcuBF4CDWlbROnRcKGTmq8DDFIkNxf0QPwHOzeKuwr2Bj0bE3jWzvZKZ+wJXAWevx+p+kJn7Z+aHgC2ATw15AxooM5+juBx4x9rhETEWOBAYeInwr4DfAr+JiB9FxKfL6bcBtqr5g1DPut8AfgPstuFbMDRtvv1n1TQhHLaWaYZVO+6PzFwFzAP2L2t4iOJo4eCI2IXi2/eiujeywSJic4q/NY+XzWEfA/6R4ojmxDoWUftzn9PAUisdFwqlWRRhQPk5Czg+Ih6l+IWbTPGk1n4/Kz97ga71WM8hEfFQRDwOHFoud2PyZxExD/glcEkOuG8kM1cDhwPHAf8KXBYRFwxcSEQcVv5SL4yIg9exvnY7kmqn7b8sM6eU/36x3lsyPNplf/wLxRHBwcAD5b/+/n9Zv01qmC0iYj7QQ3FUcA3Fl8I5mfkWcAvFkdCId1lO7c/9kIZWXOrUULgdmB4R+wJjgFcpjgCmZ+bewF1A7UmuP5Sfq6nzhr/yW8H/pDi/sBfwwwHLbDsR8X6KbVxSDrovM/fJzP0y8+qIGFHzreVCgCw8nJkXUwTsZ8tveW9GxMRyml9k5hRgAUVb8mDr3poicP+1kdu4Lu2y/RHx7f71NHBz31Ub74/7KQLgIIpAeJLiS1w7hcJbNX/MT8/iyc8nAh+LiIUUXzDHUnxZbCsdGQplm+Uc4FqKo4RtgOXAsojYiT81LQ1FfwC8EhFbUXx7alsRMQ64mqLJa9A7GjNzdc0v+jcjYucyWPtNAZ4vuy8Gruq/WqJsl17b1TVbUQTobZn52rBs0Hpqp+3PzHP71zMc27Yh2nx/PEDRdDQuM5eU9fVRPGq/3c4nAFUT2p8B/z4zuzKzC/g89TUhNVXbPOaiBWYBt1JcqfBUeVj8FLCIYfjFyszXI+KHFN+GXqa4QqLd9B/ijgRWAf8L+O56zD8SuDQidgZWUPzHPK0cdxXFVSoPRcQfKE4+3k/RPNdvTvnHYTOKn8V/3/BN2SCdvv0DbRT7IzNfi4g+3nlO4wHgwxTnNdrRscA/ZeYfaobdDnwnIt4zYHitsyLiz2v6j8nMhY0qEnzMhSSpRkc2H0mSBmcoSJIqhoIkqWIoSJIqhoIkqWIoSJIqhoIkqfL/AashfvHpHMdoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_names = [\"Vanilla\", \"DP-SGD\", \"DP-SGD-F\", \"DP-SGD-W\", \"PATE\"]\n",
    "models = [model_vanilla, model_dpsgd, model_dpsgdf, model_dpsgd_w, model_pate]\n",
    "preds = []\n",
    "for model in models:\n",
    "    preds.append(pf.utils.evaluate_model(model, test_loader))\n",
    "\n",
    "\n",
    "accuracies = {c: np.zeros(len(model_names)) for c in np.unique(test_gender)}\n",
    "for i, model in enumerate(zip(model_names, preds)):\n",
    "    correct_mask = preds[i] == y_test\n",
    "    for c in accuracies.keys():\n",
    "        class_mask = test_gender == c\n",
    "        accuracies[c][i] = np.sum(correct_mask & class_mask) / np.sum(class_mask)\n",
    "\n",
    "width = 0.2\n",
    "ind = np.arange(len(model_names))\n",
    "for i, c in enumerate(accuracies.keys()):\n",
    "    plt.bar(ind + width * i, accuracies[c] * 100, width, label=str(c))\n",
    "\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Male\", \"Female\"])\n",
    "plt.xticks(ind + width * (len(accuracies.keys()) - 1) / 2, model_names)\n",
    "plt.ylim(0, 119)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "137e9efa793c1091fd346a60a0bce44a1e8a680ca313b676547e9c83c6ce5d94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
